from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
from datetime import datetime
from app.models.material import Material

class BaseCrawler(ABC):
    """
    Abstract base class for all crawlers.
    Each specific source (YouTube, GitHub, etc.) must implement this interface.
    """
    
    def __init__(self, source_name: str):
        self.source_name = source_name

    @abstractmethod
    async def fetch(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Fetch raw data from the source.
        
        Args:
            query: Search query or keyword
            limit: Maximum number of items to fetch
            
        Returns:
            List of raw data dictionaries
        """
        pass

    @abstractmethod
    def parse(self, raw_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Parse a single raw data item into a standardized dictionary.
        
        Args:
            raw_data: Raw data item from fetch()
            
        Returns:
            Standardized dictionary or None if parsing fails
        """
        pass

    def normalize(self, parsed_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Normalize parsed data to match the Material model fields.
        Can be overridden by subclasses if specific normalization is needed.
        
        Args:
            parsed_data: Dictionary from parse()
            
        Returns:
            Dictionary ready for Material model creation
        """
        # Basic normalization (ensure required fields exist)
        return {
            "title": parsed_data.get("title", "Untitled"),
            "url": parsed_data.get("url", ""),
            "source": self.source_name,
            "type": parsed_data.get("type", "unknown"),
            "author": parsed_data.get("author"),
            "publish_date": parsed_data.get("publish_date"),
            "description": parsed_data.get("description"),
            "content_text": parsed_data.get("content_text"),
            "snippet": parsed_data.get("snippet"),
            "quality_score": 0.0, # Initial score, will be updated by processing pipeline
            "content_hash": Material.generate_content_hash(parsed_data.get("url", "") + parsed_data.get("title", "")),
            "embedding": None # Will be generated by processing pipeline
        }
